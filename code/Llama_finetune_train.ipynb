{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChDlctyE_Hus"
      },
      "outputs": [],
      "source": [
        "#Installing libraries\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3  peft trl triton\n",
        "!pip install --no-deps unsloth\n",
        "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhKkOADTBUsn"
      },
      "outputs": [],
      "source": [
        "#Loading the unsloth base model\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "\n",
        "#Insert your HF API token\n",
        "login(\"\")\n",
        "max_seq_length = 1024\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/llama-3.2-3b\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=torch.float16,\n",
        "    load_in_4bit=False,\n",
        "    low_cpu_mem_usage=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DUFA4d-CUqI"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                   \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPOd-jKpH8e3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "\n",
        "def load_balanced_split(path, frac):\n",
        "    df = pd.read_csv(path, sep=\"\\t\", index_col=0)\n",
        "    total_samples = int(len(df) * frac)\n",
        "    samples_per_class = total_samples // df['label'].nunique()\n",
        "\n",
        "    balanced = df.groupby('label', group_keys=False).apply(lambda x: x.sample(n=min(samples_per_class, len(x)), random_state=42))\n",
        "    dataset = Dataset.from_pandas(balanced, preserve_index=False)\n",
        "    return dataset\n",
        "\n",
        "\"Upload your files in the format tweet | label (Human/Machine) \"\n",
        "data_splits = {\n",
        "    \"train\": \"train.tsv\",\n",
        "    \"validation\": \"dev.tsv\",\n",
        "}\n",
        "\n",
        "raw_datasets = DatasetDict({\n",
        "    split: load_balanced_split(path, frac=0.6) ]\n",
        "    for split, path in data_splits.items()\n",
        "})\n",
        "\n",
        "print(raw_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rncuV4uJOLM"
      },
      "outputs": [],
      "source": [
        "\n",
        "label2id = {\"Human\": 0, \"Machine\": 1}\n",
        "\n",
        "def remap_labels(example):\n",
        "    example[\"label\"] = label2id[example[\"label\"]]\n",
        "    return example\n",
        "\n",
        "raw_datasets = raw_datasets.map(remap_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsOwYL6IKZMc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_prompts(data):\n",
        "    texts = []\n",
        "    for tweet in data[\"tweet\"]:\n",
        "\n",
        "        text = f'''Below is a tweet. Classify it as either Human or Machine generated.\n",
        "Tweet:\n",
        "{tweet}\n",
        "\n",
        "Classification:\n",
        "'''\n",
        "        texts.append(text)\n",
        "    return {\"text\": texts}\n",
        "\n",
        "# Apply prompt formatting\n",
        "formatted_datasets = raw_datasets.map(format_prompts, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOC2Xfyy4Uyp"
      },
      "outputs": [],
      "source": [
        "def tokenise_data(examples):\n",
        "\n",
        "    full_texts = []\n",
        "    for i, text in enumerate(examples[\"text\"]):\n",
        "        label_text = \"Human\" if examples[\"label\"][i] == 0 else \"Machine\"\n",
        "        full_text = text + label_text + tokenizer.eos_token\n",
        "        full_texts.append(full_text)\n",
        "\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        full_texts,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "\n",
        "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "    return model_inputs\n",
        "\n",
        "tokenised_datasets = formatted_datasets.map(\n",
        "    tokenise_data,\n",
        "    batched=True,\n",
        "    remove_columns=[\"tweet\", \"label\", \"text\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqDhUbl1LjHF"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForLanguageModeling\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=tokenized_dsets[\"train\"],\n",
        "    eval_dataset=tokenized_dsets[\"validation\"],\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    data_collator=data_collator,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        per_device_eval_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=10,\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=10,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=50,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=100,\n",
        "        output_dir=\"./results\",\n",
        "        optim=\"adamw_8bit\",\n",
        "        dataloader_pin_memory=False,\n",
        "        remove_unused_columns=False,\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8aOjbR-LwPj"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHGl8YYbLr25"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\"HF token\")\n",
        "model.push_to_hub(\n",
        "    \"your personal repository\"\n",
        "    tokenizer,\n",
        "    private=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGNWVm8Kzhel"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
